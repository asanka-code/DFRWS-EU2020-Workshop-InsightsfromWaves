{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for EM Data Classification\n",
    "\n",
    "This notebook includes the following activities.\n",
    "\n",
    "- High-level use of SVM and neural network classifiers.\n",
    "- Classifying dummy signal data\n",
    "- Classifying real EM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from emvincelib import iq, ml, stat\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.fftpack import fft\n",
    "from sklearn import preprocessing\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Machine Learning Concepts\n",
    "\n",
    "Machine Learning (ML) is a broad domain that develops various algorithms and statistical models to learn patterns from data and later make predictions. It is not possible to learn ML within this workshop. However, in this Jupyter-Notebook, we'll look at the basic concepts of ML and how it can help us to learn patterns in EM data. Machine Learning can be categorized into two types as **supervised** and **unsupervised** learning. In supervised learning, we provide example data and their expected classification output to an algorithm to learn. Once learned, the algorithm can produce classification output for new data. In unsupervised learning, we only provide data so that the algorithm learn patterns on its own and become capable of classifying new data.\n",
    "\n",
    "When performing ML on EM data, supervised learning is the approach we need to focus on. We can provide example EM data for specific known things occuring on computing devices and train ML models to recognize similar activities when given unknown EM data. The training data are provided in a 2-D array format named as **X**. The target classification classes for the input data are in a 1-D array named as **y**. Towards this goal, let's focus on the following two supervised ML architectures for time being.\n",
    "\n",
    "   1. Support vector machines (SVM)\n",
    "   2. Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines\n",
    "\n",
    "![alt text](./images/svm-intro.png \"Support vector machines (SVM)\")\n",
    "\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/modules/svm.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "\n",
    "clf = svm.SVC()\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.predict([[2., 2.], [-1., -2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks\n",
    "\n",
    "![alt text](./images/neural-network-intro.png \"Neural Networks\")\n",
    "\n",
    "Reference: https://scikit-learn.org/stable/modules/neural_networks_supervised.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[0., 0.], [1., 1.]]\n",
    "y = [0, 1]\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "clf.predict([[2., 2.], [-1., -2.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pre-processing Signals for Machine Learning\n",
    "\n",
    "We cannot directly use EM data files we have acquired as input to an ML model. We have to pre-process our EM data files and build the **X** and **y** data structures. Let's learn it by using a dummy dataset. Following GRC flowgraph emulates two signals that are being generated with different frequency components. Our task is to train a ML model that can distinquish between the two signal sources when a new signal file is provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "\n",
    "You can find the two data files called **4.training-class-1.cfile** and **4.training-class-2.cfile** in the data folder. Let's see the basics details about these two data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=\"./data/ml-for-signal-classification/class-1.npy\"\n",
    "file2=\"./data/ml-for-signal-classification/class-2.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq.sampleRate = 32e3\n",
    "                   \n",
    "duration1 = iq.getTimeDuration(file1, fileType=\"npy\")\n",
    "print(\"Time duration of the numpy file: \" + str(duration1) + \" seconds\")\n",
    "\n",
    "data1 = iq.getSegmentData(file1, 0, duration1, fileType='npy')\n",
    "length = len(data1)\n",
    "print(\"Number of samples in numpy data: \" + str(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration2 = iq.getTimeDuration(file2, fileType=\"npy\")\n",
    "print(\"Time duration of the numpy file: \" + str(duration2) + \" seconds\")\n",
    "\n",
    "data2 = iq.getSegmentData(file2, 0, duration2, fileType='npy')\n",
    "length = len(data2)\n",
    "print(\"Number of samples in numpy data: \" + str(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize them and see if we can visually recognize differences between the two signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq.plotFFT(data1)\n",
    "\n",
    "iq.plotFFT(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq.plotSpectrogram(data1)\n",
    "\n",
    "iq.plotSpectrogram(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Training and Testing a Machine Learning Model\n",
    "\n",
    "With these insights we have gained during the previous step, now we can generate the **X** and **y** training dataset for a classifier. We do that by sending a sliding window over the data files and converting each window data segment into a feature vector. Each feature vector is appended to the **X** matrix along with the appropriate label for it in the **y** vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iq.sampleRate = 32e3\n",
    "sliding_window = 0.1\n",
    "feature_vector_size = 50\n",
    "\n",
    "ml.loadTrainingData(file1, iq.sampleRate, feature_vector_size, sliding_window, duration1, \"Class 1\")\n",
    "ml.loadTrainingData(file2, iq.sampleRate, feature_vector_size, sliding_window, duration2, \"Class 2\")\n",
    "\n",
    "clf = ml.createClassifier()\n",
    "ml.trainAndTest(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
